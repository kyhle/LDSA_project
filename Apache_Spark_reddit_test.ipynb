{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext \n",
    "from pyspark.sql.functions import lower\n",
    "import pyspark.sql.functions as sf ##TESTING\n",
    "from operator import add\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter \n",
    "import itertools\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.87:7077\") \\\n",
    "        .appName(\"blameyben_lecture1_simple_example\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext #added\n",
    "sqlContext = SQLContext(spark_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([])\n",
    "\n",
    "#df = sqlContext.createDataFrame(spark_context.emptyRDD(), schema)\n",
    "\n",
    "#df.show()\n",
    "\n",
    "#print(df.count())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 0\n",
      "+---------------+----------------------+--------------------+--------------------+--------+----------------+-----------+-------------+------+------+-------+------------+---------+----------+--------------------+------------+-----+--------+-----------------+------------+\n",
      "|         author|author_flair_css_class|   author_flair_text|                body|can_gild|controversiality|created_utc|distinguished|edited|gilded|     id|is_submitter|  link_id| parent_id|           permalink|retrieved_on|score|stickied|        subreddit|subreddit_id|\n",
      "+---------------+----------------------+--------------------+--------------------+--------+----------------+-----------+-------------+------+------+-------+------------+---------+----------+--------------------+------------+-----+--------+-----------------+------------+\n",
      "|       Dethcola|                      |          Clairemont|            A quarry|    true|               0| 1506816000|         null| false|     0|dnqik14|       false|t3_73ieyz| t3_73ieyz|/r/sandiego/comme...|  1509189606|    3|   false|         sandiego|    t5_2qq2q|\n",
      "|     PennyBotV2|         flair2-penny1|             The Bot|[Salutations! I'm...|    true|               0| 1506816000|         null| false|     0|dnqik15|       false|t3_73g740|t1_dnqiiv7|/r/RWBY/comments/...|  1509189606|    3|   false|             RWBY|    t5_2vhg0|\n",
      "|    Sir_Firebum|             HOU-wagon|    Astros Bandwagon|I got into baseba...|    true|               0| 1506816000|         null| false|     0|dnqik16|       false|t3_73hlwn|t1_dnqc3lu|/r/baseball/comme...|  1509189606|    2|   false|         baseball|    t5_2qm7u|\n",
      "|      deanzynut|           woodcutting|        99 wcing btw|        FUCKING TORY|    true|               0| 1506816000|         null| false|     0|dnqik17|        true|t3_73gw9b|t1_dnqdo99|/r/2007scape/comm...|  1509189606|   18|   false|        2007scape|    t5_2wbww|\n",
      "|OfullOstomacheO|                  null|                null|I see a water dra...|    true|               0| 1506816000|         null| false|     0|dnqik18|       false|t3_73i6z3| t3_73i6z3|/r/mildlyinterest...|  1509189606|    1|   false|mildlyinteresting|    t5_2ti4h|\n",
      "|        PlusOn3|                 green|Sub 2:30 4x4 (2ce...|Wait. The Michiga...|    true|               0| 1506816000|         null| false|     0|dnqik19|       false|t3_73g65l|t1_dnq4z9q|/r/Cubers/comment...|  1509189606|    1|   false|           Cubers|    t5_2r6a3|\n",
      "|       yeee_bot|                  null|                null|              ye fam|    true|               0| 1506816000|         null| false|     0|dnqik1a|       false|t3_73hvr0|t1_dnqijyp|/r/teenagers/comm...|  1509189606|    2|   false|        teenagers|    t5_2rjli|\n",
      "|      grrrrreat|                  null|                null|143417804| &gt; U...|    true|               0| 1506816000|         null| false|     0|dnqik1b|        true|t3_73dvyh| t3_73dvyh|/r/4chan4trump/co...|  1509189606|    1|   false|      4chan4trump|    t5_3hds7|\n",
      "|      psych4191|  mississippistate-...|Mississippi State...|That is some chic...|    true|               0| 1506816000|         null| false|     0|dnqik1c|       false|t3_73hgz4| t3_73hgz4|/r/CFB/comments/7...|  1509189606|    2|   false|              CFB|    t5_2qm9d|\n",
      "+---------------+----------------------+--------------------+--------------------+--------+----------------+-----------+-------------+------+------+-------+------------+---------+----------+--------------------+------------+-----+--------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#file = open('testfiles/sample_data.json')\n",
    "file = open('testfiles/sample_data-Copy1.json')\n",
    "content = file.read()\n",
    "array = content.split('\\n')\n",
    "\n",
    "file.close()\n",
    "    \n",
    "#subreddit_array = [\"Cubers\", \"mildlyinteresting\",\"4chan4trump\", \"The_Donald\"]\n",
    "\n",
    "df = sqlContext.createDataFrame(spark_context.emptyRDD(), schema)\n",
    "\n",
    "for comment in array:\n",
    "    \n",
    "    rddjson = spark_context.parallelize([comment])\n",
    "    \n",
    "    current_df = sqlContext.read.json(rddjson)\n",
    "    \n",
    "    count = df.count()\n",
    "\n",
    "    if count == 0:\n",
    "        df = current_df\n",
    "        print(\"count = 0\")\n",
    "    else:\n",
    "        df = df.union(current_df)\n",
    "\n",
    "        #print(count)\n",
    "    \n",
    "\n",
    "#df.show()\n",
    "df.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|         author|\n",
      "+---------------+\n",
      "|       Dethcola|\n",
      "|     PennyBotV2|\n",
      "|    Sir_Firebum|\n",
      "|      deanzynut|\n",
      "|OfullOstomacheO|\n",
      "|        PlusOn3|\n",
      "|       yeee_bot|\n",
      "|      grrrrreat|\n",
      "|      psych4191|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"author\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
