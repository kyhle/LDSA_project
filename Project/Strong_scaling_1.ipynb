{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong scaling test 1 (Also used as Weak scaling test 1)\n",
    "# 1 node\n",
    "# 9 GB of data\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext \n",
    "import json\n",
    "import timeit\n",
    "import pyspark.sql.functions as f \n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.225:7077\") \\\n",
    "        .appName(\"Strong_scaling_1\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.cores.max\",1)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  355.51083533093333 s\n",
      "CPU times: user 76.7 ms, sys: 43.5 ms, total: 120 ms\n",
      "Wall time: 5min 55s\n"
     ]
    }
   ],
   "source": [
    "#In this cell, the Reddit data is fetched from HDFS, read as a JSON-file and saved to the variable ’df’. The wall clock time of this operation is measured and printed using timeit.default_timer()\n",
    "\n",
    "start_time_0 = timeit.default_timer()\n",
    "\n",
    "df = spark_session.read.json('hdfs://192.168.2.225:9000/reddit/RC_2012-02')\n",
    "\n",
    "elapsed_0 = timeit.default_timer() - start_time_0\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_0, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  1.0999257609946653 s\n"
     ]
    }
   ],
   "source": [
    "### PRE-PROCESSING ###\n",
    "#In this cell the data is preprocessed. Most columns are dropped and comments that have been deleted are removed.\n",
    "\n",
    "initial_start_time = timeit.default_timer()\n",
    "\n",
    "if 'author_cakeday' in df.columns:\n",
    "        current_df = df.drop('author_cakeday')\n",
    "        \n",
    "df = df.drop('author_flair_css_class','author_flair_text','can_gild','distinguished','edited','id','is_submitter','link_id','parent_id','permalink','retrieved_on','stickied','subreddit_id')\n",
    "\n",
    "df = df.filter((df.body != '[deleted]'))\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - initial_start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"Time elapsed: \", elapsed, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          subreddit|  count|\n",
      "+-------------------+-------+\n",
      "|          AskReddit|1974313|\n",
      "|              funny| 767566|\n",
      "|               pics| 601277|\n",
      "|            atheism| 482672|\n",
      "|             gaming| 477368|\n",
      "|                WTF| 391188|\n",
      "|           politics| 363712|\n",
      "|              trees| 296983|\n",
      "|fffffffuuuuuuuuuuuu| 294680|\n",
      "|               IAmA| 267945|\n",
      "+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time elapsed:  389.4198994738981 s\n",
      "CPU times: user 111 ms, sys: 32 ms, total: 143 ms\n",
      "Wall time: 6min 29s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 1 ###\n",
    "\n",
    "#In this cell the data is processed to show the most frequently occurring subreddits that reddit comments are posted in, in descending order.\n",
    "\n",
    "start_time_1 = timeit.default_timer()\n",
    "\n",
    "df.groupBy('subreddit').count().sort(\"count\", ascending = False).show(10)\n",
    "\n",
    "elapsed_1 = timeit.default_timer() - start_time_1\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_1,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|wordCount| count|\n",
      "+---------+------+\n",
      "|        5|578020|\n",
      "|        6|576405|\n",
      "|        4|557292|\n",
      "|        7|554545|\n",
      "|        8|527944|\n",
      "|        1|509309|\n",
      "|        3|508649|\n",
      "|        9|495282|\n",
      "|       10|465635|\n",
      "|        2|454971|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time elapsed:  449.60605269798543 s\n",
      "CPU times: user 134 ms, sys: 24.1 ms, total: 158 ms\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 2 ###\n",
    "#In this cell, the number of words in each comment is counted and saved in the new column ’wordCount’. \n",
    "\n",
    "start_time_2 = timeit.default_timer()\n",
    "\n",
    "df = df.withColumn('wordCount', f.size(f.split(f.col('body'), ' ')))\n",
    "\n",
    "\n",
    "df.groupBy('wordCount').count().sort(\"count\", ascending = False).show(10)   \n",
    "\n",
    "elapsed_2 = timeit.default_timer() - start_time_2\n",
    "\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_2,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wordcount in comment:  32.56660286612964  words.\n",
      "Time elapsed:  340.74685820401646 s\n",
      "CPU times: user 116 ms, sys: 36.7 ms, total: 153 ms\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 3 ###\n",
    "#In this cell, the mean of all values in the new column ’wordCount’ is calculated and printed to show the average word count in a comment.\n",
    "\n",
    "start_time_3 = timeit.default_timer()\n",
    "\n",
    "df_stats = df.select(f.mean(f.col('wordCount')).alias('mean')).collect()  \n",
    "\n",
    "mean = df_stats[0]['mean']\n",
    "\n",
    "print(\"Average wordcount in comment: \", mean, \" words.\")\n",
    "\n",
    "\n",
    "elapsed_3 = timeit.default_timer() - start_time_3\n",
    "print(\"Time elapsed: \", elapsed_3,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed:  1180.9862001820002 s\n"
     ]
    }
   ],
   "source": [
    "### TOTAL TIME ELAPSED (PROCESSING) ###\n",
    "#Here the total time elapsed since the preprocessing of the data is printed.\n",
    "\n",
    "total_elapsed = timeit.default_timer() - initial_start_time\n",
    "\n",
    "print(\"Total time elapsed: \", total_elapsed, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
