{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strong scaling test 1 (Also used as 'Weak scaling test 1')\n",
    "# 1 node\n",
    "# 9 GB of data\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext \n",
    "import json\n",
    "import timeit\n",
    "import pyspark.sql.functions as f \n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.225:7077\") \\\n",
    "        .appName(\"Strong_scaling_1\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.cores.max\",1)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  352.7321423009271 s\n"
     ]
    }
   ],
   "source": [
    "#In this cell, the Reddit data is fetched from HDFS, read as a JSON-file and saved to the variable ’df’.\n",
    "#The wall clock time of this operation is measured and printed using timeit.default_timer()\n",
    "\n",
    "start_time_0 = timeit.default_timer()\n",
    "\n",
    "df = spark_session.read.json('hdfs://192.168.2.225:9000/reddit/RC_2012-02')\n",
    "\n",
    "elapsed_0 = timeit.default_timer() - start_time_0\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_0, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  0.08971537696197629 s\n"
     ]
    }
   ],
   "source": [
    "### PRE-PROCESSING ###\n",
    "#In this cell the data is preprocessed. Most columns are dropped and comments that have been deleted are removed.\n",
    "\n",
    "initial_start_time = timeit.default_timer()\n",
    "\n",
    "#As the column 'author_cakeday' does not exist in all of the reddit JSON-files, it is specifically checked for and only dropped in the case that it does exists.'.\n",
    "if 'author_cakeday' in df.columns:\n",
    "        current_df = df.drop('author_cakeday')\n",
    "        \n",
    "df = df.drop('author_flair_css_class','author_flair_text','can_gild','distinguished','edited','id','is_submitter','link_id','parent_id','permalink','retrieved_on','stickied','subreddit_id')\n",
    "\n",
    "df = df.filter((df.body != '[deleted]'))\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - initial_start_time\n",
    "\n",
    "\n",
    "\n",
    "print(\"Time elapsed: \", elapsed, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          subreddit|  count|\n",
      "+-------------------+-------+\n",
      "|          AskReddit|1974313|\n",
      "|              funny| 767566|\n",
      "|               pics| 601277|\n",
      "|            atheism| 482672|\n",
      "|             gaming| 477368|\n",
      "|                WTF| 391188|\n",
      "|           politics| 363712|\n",
      "|              trees| 296983|\n",
      "|fffffffuuuuuuuuuuuu| 294680|\n",
      "|               IAmA| 267945|\n",
      "+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time elapsed:  232.84774716407992 s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 1 ###\n",
    "\n",
    "#In this cell the data is processed to show the most frequently occurring subreddits \n",
    "#that reddit comments are posted in, in descending order.\n",
    "\n",
    "start_time_1 = timeit.default_timer()\n",
    "\n",
    "df.groupBy('subreddit').count().sort(\"count\", ascending = False).show(10)\n",
    "\n",
    "elapsed_1 = timeit.default_timer() - start_time_1\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_1,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|wordCount| count|\n",
      "+---------+------+\n",
      "|        5|578020|\n",
      "|        6|576405|\n",
      "|        4|557292|\n",
      "|        7|554545|\n",
      "|        8|527944|\n",
      "|        1|509309|\n",
      "|        3|508649|\n",
      "|        9|495282|\n",
      "|       10|465635|\n",
      "|        2|454971|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time elapsed:  361.22249193594325 s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 2 ###\n",
    "#In this cell, the number of words in each comment is counted and saved in the \n",
    "#new column ’wordCount’. \n",
    "\n",
    "start_time_2 = timeit.default_timer()\n",
    "\n",
    "df = df.withColumn('wordCount', f.size(f.split(f.col('body'), ' ')))\n",
    "\n",
    "\n",
    "df.groupBy('wordCount').count().sort(\"count\", ascending = False).show(10)   \n",
    "\n",
    "elapsed_2 = timeit.default_timer() - start_time_2\n",
    "\n",
    "\n",
    "print(\"Time elapsed: \", elapsed_2,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average wordcount in comment:  32.56660286612964  words.\n",
      "Time elapsed:  344.46260858501773 s\n"
     ]
    }
   ],
   "source": [
    "### MAIN PROCESSING - CELL 3 ###\n",
    "#In this cell, the mean of all values in the new column ’wordCount’ is calculated \n",
    "#and printed to show the average word count in a comment.\n",
    "\n",
    "start_time_3 = timeit.default_timer()\n",
    "\n",
    "df_stats = df.select(f.mean(f.col('wordCount')).alias('mean')).collect()  \n",
    "\n",
    "mean = df_stats[0]['mean']\n",
    "\n",
    "print(\"Average wordcount in comment: \", mean, \" words.\")\n",
    "\n",
    "\n",
    "elapsed_3 = timeit.default_timer() - start_time_3\n",
    "print(\"Time elapsed: \", elapsed_3,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed:  938.7271537180059 s\n"
     ]
    }
   ],
   "source": [
    "### TOTAL TIME ELAPSED (PROCESSING) ###\n",
    "#Here the total time elapsed since the preprocessing of the data is printed.\n",
    "\n",
    "total_elapsed = timeit.default_timer() - initial_start_time\n",
    "\n",
    "print(\"Total time elapsed: \", total_elapsed, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
